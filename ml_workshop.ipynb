{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=blue>WWU CS Mentors Machine Learning Workshop</font>\n",
    "#### _By Robin Cosbey and Josh Myers-Dean_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What we will accomplish in this excersize \n",
    "- Learn how to read in a CSV and do some exploratory data analysis\n",
    "- Build a decision tree model from scratch\n",
    "- Use our model to predict // TODO WORD THIS BETTER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis\n",
    "First we will read in a csv file containing information about different species of iris flowers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal-length</th>\n",
       "      <th>sepal-width</th>\n",
       "      <th>petal-length</th>\n",
       "      <th>petal-width</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal-length  sepal-width  petal-length  petal-width        class\n",
       "0           5.1          3.5           1.4          0.2  Iris-setosa\n",
       "1           4.9          3.0           1.4          0.2  Iris-setosa\n",
       "2           4.7          3.2           1.3          0.2  Iris-setosa\n",
       "3           4.6          3.1           1.5          0.2  Iris-setosa\n",
       "4           5.0          3.6           1.4          0.2  Iris-setosa"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Pandas is a great library for data manipulation and visualizations,\n",
    "here we read in the csv and represent it as a dataframe (df). I like to think\n",
    "of these as fancy dictionaries.\n",
    "'''\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"iris.csv\")\n",
    "df.head() # allows us to peak at the first 5 rows of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our data has 4 different features we can use and seem to be labelled by what class of iris they are. <br />\n",
    "Now that we've got a sneak peek of our data, let's try and see what else we can find out about it before we move on to our model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe Shape:  (150, 5) \n",
      "\n",
      "Summary Statistics:\n",
      "\n",
      "        sepal-length  sepal-width  petal-length  petal-width\n",
      "count    150.000000   150.000000    150.000000   150.000000\n",
      "mean       5.843333     3.054000      3.758667     1.198667\n",
      "std        0.828066     0.433594      1.764420     0.763161\n",
      "min        4.300000     2.000000      1.000000     0.100000\n",
      "25%        5.100000     2.800000      1.600000     0.300000\n",
      "50%        5.800000     3.000000      4.350000     1.300000\n",
      "75%        6.400000     3.300000      5.100000     1.800000\n",
      "max        7.900000     4.400000      6.900000     2.500000\n"
     ]
    }
   ],
   "source": [
    "print(\"Dataframe Shape: \", df.shape,\"\\n\")\n",
    "print(\"Summary Statistics:\\n\\n\", df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Awesome! So now we have some useful information about the dataset we are working with. We can think of our dataset as a 150x5 matrix, or simply view it as a CSV with 150 entries with each entry having 5 features.\n",
    "<br /> \n",
    "<br />\n",
    "The summary statistics give us a view into how the data is distributed, let's take a more visual look at our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAEICAYAAAB/Dx7IAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAHPJJREFUeJzt3XucHFWd9/HPlzCQEEK4jWiMYRAUx4TFy4i3WWRQWdR9vKy6EB4vrNG4ukbx0cVofAnZ3Twvoquru7qukSAoZkQUXE1UwMdkcRCQhJuBAeUSIITLoBKSGCGE3/PHOSOdZma6Jume7pp8369Xv6a7+tSpX52u/tXpUzVVigjMzKw89mh2AGZmNjpO3GZmJePEbWZWMk7cZmYl48RtZlYyTtxmZiXjxG0tT9JfSrp1J+f9iaR31zGWSZJ+JGmjpAvrVW+NZdZ1Haz8nLjrSFK3pF/mL/XvJV0h6SXNjqvRJM2UdGle54clrZH0+vzecZLWj7K+kHTE4OuI+EVEHFlgvjMlnV85LSJeFxHnjWb5NbwNOAQ4KCLevquVFWmfnVkHSR25HTfnxwOSlkt67SjqOFVS32iWuzPGajnjiRN3nUjaD1gO/AdwIPBMYCHwaDPjGi0lo90ufgRcBjwdeBrwYeCResfWIg4FfhMRj492Rkl7jrL8znwW1faPiH2Bo0mf0cWSTt3FOq3ZIsKPOjyALuDhEd4/Ezi/4nUHEMCe+fUq4F+AXwKbScnwIODbpCR4DdBRMX8AHwR+C2wC/hk4PM//CPBdYK9c9gDSTmUA+EN+Pr2irlXAIuAKYCvwj8Caqvj/D/DfQ6zXwTmW/Yd4b3Ku74m8TpuBacAxwJXAw8B9wJcrYr0817cllz8JOA5YX1HvJ4B783rfCrwaOBF4DNiW57uhYt3eWzHv+4D+PO/NwIuGq3OI9VlYtYw5pM7Pp4G7gAeBbwJTqz7jOcDdwOVD1Fm9btWfxRGV65Bf/w+wEXgIuGCY7W1w2XtWTf848ACwR349H7i9oj3ekqd3An8Ctud1fThPfwNwHWkbuwc4s6LuicD5wO/yZ3sNcEh+byqwNH/e95K29QnDLcePGvmm2QGMlwewX95gzwNeBxxQ9f6Z1E7ct5GS79T8JfoN8Bpgz5wQvlExfwD/nZc7k9Sz/3/Asyvmf3cuexDwVmAfYApwIfCDirpW5cQyMy9rb+D3QGdFmeuAtw6x3iLtPJYDbx78ola8fxwViSlPezHwsrysDlIiPa1q3Y4Yqg7gyJwwplW04+FDtXHFug0mvbfnpPGSHPcRpB70sHUOsb7Vn+N78uf2bGBf4CLgW1Wf8TdJO7FJQ9S3Q/sM8Vm0Va1DL7CAtMOYCHQPE+fgsqsT97Pz9M6KNpmW6zuJtMN8Rn7vVKBviHiPyuX/grQTeHN+7/2kDsc+pKT8YmC//N7FwNdyOzwN+BXw/uGW48fIDw+V1ElEPAJ0k74UXwcGJP1Q0iGjqOYbEXF7RGwEfgLcHhE/i/Sz/ELghVXlPxsRj0TETcBa4NKIuKNi/hfm2H4XEd+PiD9GxCZSj+5VVXWdGxE3RcTjEfEocAHwDkhj2KREsHyI9Q6gB1gHfB64T9Llkp4z3EpGxJqIuCovax3pC10dz3C2k3Ysz5fUFhHrIuL2gvO+l9Rm10RyW0TctYt1/m/gC7ndNwOfBE6uGhY5MyK2RMTWgnVWfhbbqt7bRtrZTIuIP0XEaMeGN+S/BwJExIURsSEinoiIC0g74WOGmzkiVkXEr3P5G0k7ksHPbhupk3BERGzPn/Mj+TvwetLOeUtEPAj8G3DyKGO3zIm7jiKiPyJOjYjpwCxST+aLo6jigYrnW4d4ve/OlJe0j6SvSbpL0iOk4Yj9JU2oKH9PVd3nAadIEvBO4Ls5oT9FRKyPiA9FxOGkpLKF1MsckqTn5gNl9+d4/i9pyKWmiLgNOI3U831Q0nckTSsyL/As0rBAPeucRhomGXQXqadcucOubttaRip/OunXwq8k3STpPaOs+5n57+8BJL1L0vX5oPLDpO122M9C0kslrZQ0IGkj8PcV5b8FXAJ8R9IGSZ+V1EbaJtpIO/XB5XyN1PO2neDE3SARcQtwLumLACmZ7VNR5OljGM7HSMMBL42I/YBj83RVlNnhMpERcRVpPPcvgVNIX8qaIuIe4Cs8ud5DXX7yq8AtwHNyPJ+qiqXWMpZFRDcpIQSweIRlVbqHNBQ1mjpr2ZDnGTQDeJwdd6KjvQTnsOUj4v6IeF9ETCMNTfxn5Rk4BbyFNBZ/q6RDSb8OP0Q6S2Z/0i+3wc9iqDiWAT8EnhURU4H/GiwfEdsiYmFEPB94BfDXwLtI7f4ocHBE7J8f+0XEzFrra0Nz4q4TSc+T9DFJ0/PrZwGzgatykeuBYyXNkDSV9JN6rEwh9cAflnQgcEbB+b5JOnC4bbif5JIOkLRQ0hGS9pB0MGncd3C9HwAOyutcGc8jwGZJzwM+UFXtA6Sx2KGWd6Sk4yXtTTqoNXjwc3C+jhHOxDgb+LikF+czNo6QdGiNOmvpBT4q6TBJ+5J+PVwQO3HWSRGS3j64jZEONAcFYpV0iKQPkT77T0bEE6Tx5iAdtEbS3/HkDhdSe06XtFfFtCnA7yPiT5KOIe3UB5fRI+mo/EvuEdLQyRMRcR9wKfB5Sfvl7eRwSa8aYTk2Aifu+tkEvBS4WtIWUuJaS+rtEhGXkcaNbwTWMMR4cQN9EZhEOgvhKuCnBef7FumLfP4IZR4jjX//jPRlXUvqXZ0Kf/7l0QvckX8mTyOd2XAKqc2+TmqXSmcC5+Xyf1v13t7AWXld7if93B7cCQ7+Q8zvJF1bHWhEXEga31+Wl/0D0ljvSHXWcg6pnS4H7iQl/nkF590ZLyFtY5tJPd+PRMQdI5R/OG+PvyaNM789Is4BiIibScclriQlz6NIZ7MM+jlwE3C/pIfytA8C/yRpE/AZ0tlLg54OfI+0HfSTzn4Z/KX2LmAv0kHzP+RyzxhhOTYCpWNLZk8laRLpZ/WLIuK3zY7HzBL3uG0kHwCucdI2ay2j+k8u231IWkc66PTmJodiZlU8VGJmVjIeKjEzK5mGDJUcfPDB0dHR0YiqzczGpTVr1jwUEe1FyjYkcXd0dLB69epGVG1mNi5Juqt2qcRDJWZmJePEbWZWMk7cZmYlUyhxS/povhLZWkm9kiY2OjAzMxtazcQt6ZmkW1F1RcQs0gXSfR1dM7MmKTpUsicwKV8cfh+evBi7mZmNsZqJOyLuBf6VdDul+4CNEXFpdTlJcyWtlrR6YGCg/pGamRlQbKjkAOBNwGGku31MlvSO6nIRsSQiuiKiq7290DnkZma2E4oMlbwGuDMiBvL97y4i3d2iZUmq68PMrJUUSdx3Ay/L9y0U8GrSRdJbVpG7JB/6ieWF76hsZtZKioxxX026W8W1pLto7AEsaXBcZmY2jELXKomIMyh+n0IzM2sg/+ekmVnJOHGbmZWME7eZWck4cZuZlYwTt5lZyThxm5mVjBO3mVnJOHGbmZWME7eZWck4cZuZlYwTt5lZyThxm5mVjBO3mVnJOHGbmZWME7eZWck4cZuZlUyRmwUfKen6iscjkk4bi+DMzOypat4BJyJuBV4AIGkCcC9wcYPjMjOzYYx2qOTVwO0RcVcjgjEzs9pGm7hPBnqHekPSXEmrJa0eGBjY9cjMzGxIhRO3pL2ANwIXDvV+RCyJiK6I6Gpvb69XfGZmVmU0Pe7XAddGxAONCsbMzGqreXCywmyGGSYxs2Ik1bW+iKhrfVYOhXrckiYDrwUuamw4ZuNbRBR6HPqJ5YXK2e6pUI87IrYABzU4FjMzK8D/OWlmVjJO3GZmJePEbWZWMk7cZmYl48RtZlYyTtxmZiXjxG1mVjJO3GZmJePEbWZWMqO5VklLOHrhpWzcuq0udXXMX1GXeqZOauOGM06oS11mZrWULnFv3LqNdWe9odlh7KBeOwAzsyI8VGJmVjJO3GZmJePEbWZWMk7cZmYl48RtZlYyRe+As7+k70m6RVK/pJc3OjAzMxta0dMBvwT8NCLelu/2vk8DYzIzsxHUTNySpgLHAqcCRMRjwGONDcvMzIZTZKjkMGAA+Iak6ySdnW8evANJcyWtlrR6YGCg7oGamVlSJHHvCbwI+GpEvBDYAsyvLhQRSyKiKyK62tvb6xymmZkNKpK41wPrI+Lq/Pp7pERuZmZNUDNxR8T9wD2SjsyTXg3c3NCozMxsWEXPKpkHfDufUXIH8HeNC8nMzEZSKHFHxPVAV4NjKWRK53yOOu8pQ+xNNaUToLWuWGhm41fpLuu6qf8sX9bVzHZr/pd3M7OSceI2MysZJ24zs5Jx4jYzKxknbjOzknHiNjMrGSduM7OSceI2MysZJ24zs5Jx4jYzKxknbjOzknHiNjMrGSduM7OSceI2MysZJ24zs5Jx4jYzK5lCN1KQtA7YBGwHHo+Ipt4Np9VuXDB1UluzQ7AWcPTCS9m4dVvd6qvXdj51Uhs3nHFCXeqy1jCaO+D0RMRDDYukoHrd/aZj/oqWu5OOldvGrdtacptqtY6O7ToPlZiZlUzRxB3ApZLWSJo7VAFJcyWtlrR6YGCgfhGamdkOiibu7oh4EfA64B8kHVtdICKWRERXRHS1t7fXNUgzM3tSocQdEffmvw8CFwPHNDIoMzMbXs3ELWmypCmDz4ETgLWNDszMzIZW5KySQ4CLJQ2WXxYRP21oVGZmNqyaiTsi7gCOHoNYzMysAJ8OaGZWMk7cZmYl48RtZlYyTtxmZiXjxG1mVjJO3GZmJePEbbukt7eXWbNmMWHCBGbNmkVvb2+zQzIb90ZzWVezHfT29rJgwQKWLl1Kd3c3fX19zJkzB4DZs2c3OTqz8cs9bttpixYtYunSpfT09NDW1kZPTw9Lly5l0aJFzQ7NbFxz4rad1t/fT3d39w7Turu76e/vb1JEZrsHD5XYTuvs7KSvr4+enp4/T+vr66Ozs7OJUTXPlM75HHXe/GaH8RRTOgFa7848tvPGZeLOF8SqXW5xsfoiYheiGb8WLFjASSedxOTJk7n77ruZMWMGW7Zs4Utf+lKzQ2uKTf1n+dZlNibGZeJ2oh17bnOzseMxbttpixYt4oILLuDOO+/kiSee4M477+SCCy7wwUmzBnPitp3W39/P+vXrdziPe/369T44adZg43KoxMbGtGnTOP3001m2bNmfz+M+5ZRTmDZtWrNDMxvXCve4JU2QdJ2k5Y0MyMql+kBw0QPDZrbzRjNU8hHAv4HtzzZs2MDixYuZN28eEydOZN68eSxevJgNGzY0OzSzca1Q4pY0nXQi6NmNDcfKpLOzk+nTp7N27Vq2b9/O2rVrmT59+m57HrfZWCk6xv1F4HRgynAFJM0F5gLMmDFj1yOzljHS8Mfxxx8/6nl86qDZrqnZ45b018CDEbFmpHIRsSQiuiKiq729vW4BWvNFxLCPZcuWMXPmTNAezJw5k2XLlo1Y3knbbNcV6XG/EnijpNcDE4H9JJ0fEe9obGhWBrNnz2b27Nl0zF/B2hb8r0Gz8ahmjzsiPhkR0yOiAzgZ+LmTtplZ8/gfcMzMSmZU/4ATEauAVQ2JxMzMCnGP28ysZJy4zcxKxonbzKxknLjNzErGidvMrGScuM3MSsaJ28ysZJy4zcxKxonbzKxknLjNzErGidvMrGScuM3MSsZ3ed+NHb3wUjZu3Va3+jrmr6hLPVMntXHDGSfUpS6z8ciJeze2ces21rXgzQ/qtQMwG688VGJmVjJO3GZmJVPkZsETJf1K0g2SbpK0cCwCMzOzoRUZ434UOD4iNktqA/ok/SQirmpwbGZmNoSaiTsiAticX7blRzQyKDMzG16hs0okTQDWAEcAX4mIq4coMxeYCzBjxox6xmgNMqVzPkedN7/ZYTzFlE6A1jvbxaxVFErcEbEdeIGk/YGLJc2KiLVVZZYASwC6urrcIy+BTf1n+XRAsxIa1VklEfEwsBI4sTHhmJlZLUXOKmnPPW0kTQJeC9zS6MDMzGxoRYZKngGcl8e59wC+GxHLGxuWmZkNp8hZJTcCLxyDWKwJWnE8eeqktmaHYNbSfK2S3Vg9D0x2zF/Rkgc6zcYj/8u7mVnJOHGbmZWME7eZWck4cZuZlYwTt5lZyThxm5mVjE8HNLPSklTX+tLFUFufe9xmVloRUehx6CeWFypXFk7cZmYl48RtZlYyTtxmZiXjxG1mVjJO3GZmJePEbWZWMj6P22oqeq6sFherr0ynXZm1Iiduq8mJ1qy1FLnn5LMkrZR0s6SbJH1kLAKzcujt7WXWrFlMmDCBWbNm0dvb2+yQzMa9Ij3ux4GPRcS1kqYAayRdFhE3Nzg2a3G9vb0sWLCApUuX0t3dTV9fH3PmzAFg9uzZTY7ObPyq2eOOiPsi4tr8fBPQDzyz0YFZ61u0aBFLly6lp6eHtrY2enp6WLp0KYsWLWp2aGbj2qjOKpHUQbpx8NVDvDdX0mpJqwcGBuoTnbW0/v5+uru7d5jW3d1Nf39/kyIy2z0UTtyS9gW+D5wWEY9Uvx8RSyKiKyK62tvb6xmjtajOzk76+vp2mNbX10dnZ2eTIjLbPRRK3JLaSEn72xFxUWNDsrJYsGABc+bMYeXKlWzbto2VK1cyZ84cFixY0OzQzMa1mgcnlU7iXQr0R8QXGh+SlcXgAch58+bR399PZ2cnixYt8oFJswYrclbJK4F3Ar+WdH2e9qmI+HHjwrKymD17thO12Rirmbgjog+o720mzMxqOHrhpWzcuq1u9XXMX7HLdUyd1MYNZ5xQh2h2jf9z0sxa0sat21h31huaHcYO6pH868EXmTIzKxknbjOzknHiNjMrGY9xm9VRq4yBVpo6qa3ZIVidOXGb1Uk9D6R1zF/RcgfmrHV4qMTMrGScuM3MSsaJ28ysZJy4zcxKxonbzKxknLjNzErGpwOaWUua0jmfo86b3+wwdjClE6D5p2k6cZtZS9rUf1bLncveKv9g5aESM7OSceI2MyuZmolb0jmSHpS0diwCMjOzkRXpcZ8LnNjgOMzMrKCaiTsiLgd+PwaxmJlZAXU7q0TSXGAuwIwZM+pVrdm4IhW/fasW1y4TEbsQjZVV3Q5ORsSSiOiKiK729vZ6VWs2rkREXR+2e/JZJWZmJePEbWZWMkVOB+wFrgSOlLRe0pzGh2VmZsOpeXAyImaPRSBmZlaMh0rMzErGidvMrGScuM3MSsaJ28ysZJy4zcxKxonbzKxknLjNzErGidvMrGScuM3MSsaJ28ysZJy4zcxKxonbzKxk6nYHHDOzeuuYv6LZIexg6qS2ZocAOHGbWYtad9Yb6lZXx/wVda2v2TxUYmZWMk7cZmYlUyhxSzpR0q2SbpM0v9FBmZnZ8GqOcUuaAHwFeC2wHrhG0g8j4uZGB2dmNhJJxcsurl0mInYhmrFT5ODkMcBtEXEHgKTvAG8CnLjNrKnKkmjrrchQyTOBeyper8/TdiBprqTVklYPDAzUKz4zM6tSt4OTEbEkIroioqu9vb1e1ZqZWZUiifte4FkVr6fnaWZm1gRFEvc1wHMkHSZpL+Bk4IeNDcvMzIZT8+BkRDwu6UPAJcAE4JyIuKnhkZmZ2ZAK/ct7RPwY+HGDYzEzswL8n5NmZiXjxG1mVjJqxAnskgaAu+pecX0dDDzU7CDGEbdnfbk966sM7XloRBQ6l7ohibsMJK2OiK5mxzFeuD3ry+1ZX+OtPT1UYmZWMk7cZmYlszsn7iXNDmCccXvWl9uzvsZVe+62Y9xmZmW1O/e4zcxKyYnbzKxkxnXilnScpOXDvLdKUl1PD5K0v6QPFll+me3Kekn6J0mvGanO/PwVFe+dK+ltOx/x2JF0qqRpBcoNuU6SOiStbUBcpW1T2PV2LbiMX9aqU9JpkvapeG/zzixrV43rxN0E+wMfrFlqNxYRn4mIn9UodhzwihplWtWpQM0E0wTHUd42hTFo14go0j6nAfvULNVgTU/ckiZLWiHpBklrJZ0k6cWS/kfSGkmXSHpGLrtK0pckXZ/LHpOnHyPpSknXSfqlpCNHGcMJef5rJV0oad88fZ2khXn6ryU9L09vl3SZpJsknS3pLkkHA2cBh+f4Pper31fS9yTdIunbGs1N8nZBM9pV0kskXZSfv0nSVkl7SZooafDWd5W9lxNzu1wL/E2e1gH8PfDRHM9f5uqPzTHcMZY9xdwDHvzs+vNnuc9QbZnj6gK+nWOfJOkzkq7J7bpkNJ+/pAmSPpfnv1HS+/P04/Jn9pTtStLr87Q1kv5d0vJWa9Mc55i2q6SvSHpjfn6xpHPy8/dIWpSfb85/JenLSjdI/xnwtDz9w6Sdx0pJKyvqXpS/Z1dJOqQBzfVUEdHUB/BW4OsVr6cCvwTa8+uTSJeSBVg1WBY4Flibn+8H7Jmfvwb4fn5+HLB8mOWuIm0MBwOXA5Pz9E8An8nP1wHz8vMPAmfn518GPpmfnwhErqdjMKaK5W8k3XxiD+BKoHu8tivpapN35Of/SrqW+yuBVwG9efq5wNuAiaRb4j0HEPDdwTqBM4GPV9R7LnBhbsPnk+6BOlbbZ0f+fF+ZX58D/GONtuyqmP/AiuffAv5XZTsMs7zB9p8LfDo/3xtYDRw23HZV0aaH5Xl6W7FNm9SuJwOfy89/BVyVn38D+Kv8fHP++zfAZaTLWE8DHh6sk5QTDq6oNyqW/dnBz6vRj0KXdW2wXwOfl7QYWA78AZgFXJZ3ohOA+yrK9wJExOWS9pO0PzAFOE/Sc0gN2TaK5b+MtOFekZe3F+mLMOii/HcNuVdI+pK8JcfxU0l/GKH+X0XEegBJ15M22L5RxLezxrxdI127/XZJnaSbTH+BtCOYAPyiqvjzgDsj4rcAks4nJarh/CAingBuHrNezZPuiYgr8vPzgU8xcltW6pF0Ounn9YHATcCPCi73BOAvKnrDU0k7uscYervaTNpx3pnL99K6bQpj266/AE6T9HzSjc4PUPrF+XLgw1VljyV1NLYDGyT9fIR6HyN9vyDliNeOULZump64I+I3kl4EvB74F+DnwE0R8fLhZhni9T8DKyPiLfln4arqmSRdAhwCrI6I91a+BVwWEbOHWd6j+e92dq69Hq14vrN1jFoT2/Vy4HXANuBnpB7QBFJvaldUtuOYDDdVqG6bTYzclgBImgj8J6mneI+kM0m94soyLwW+ll9+Brix8m3SL75LquY5jvpsV81sUxjDdo2IH+bOyImkbfRA4G9JvexNu7AO2yJ3txnD73crjHFPA/4YEecDnwNeCrRLenl+v03SzIpZTsrTu4GNEbGR1BMZvA/mqUMtJyL+KiJeUJW0Aa4CXinpiFzvZEnPrRH2FaQPHUknAAfk6ZtIvdSma2K7/oJ0AOfKiBgADgKOBKrPlLgF6JB0eH5dueNsmXbMZgy2G3AKaZsZri0rYx9MJg8pHTd5yjhyRFyd2+8FEVF9S8BLgA9IasvLea6kySPEeSvw7LyThfyZDhFXqxjrdr2KtG1eTtpOP85TfwmS3z9J6RjDM4Ceivdaoh2b3uMGjgI+J+kJUi/tA8DjwL9LmkqK8Yukn0IAf5J0Heln+3vytM+SftJ/GlgxmoVHxICkU4FeSXvnyZ8GfjPCbAtz+XeShlXuBzZFxKOSrlA6nesno42lzprVrleTeuCX59c3Ak+v6JUAEBF/kjQXWCHpj6Qv0OAX4kfA9yS9CZg3inVulFuBf8gHtG4G/oOUVIdqy3OB/5K0lfQz/Oukndb9pDH/0TibNARybT74NgC8ebjCEbFV6XTUn0raUrW8VmtTGPt2/QVwQkTcJukuUq97qMR9MXB8juludhw6XUJq3w0R0TPEvGOiVP/yLmkV6QDL6ibHsTewPY/pvhz4akS8oJkx7YpWaddWlHuvyyNiVpNDKUTSvhGxOSf6rwC/jYh/a3Zc1crWrq2mFXrcZTQD+K6kPUgHJ97X5HjMBr1P0rtJB9mv48lxXhtHStXjNjOzFjg4aWZmo+PEbWZWMk7cZmYl48RtZlYyTtxmZiXz/wFb6pJ0zznMuAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "ax = df.boxplot(grid=False)\n",
    "ax.set_title(\"Summary Statistics for Iris Dataset\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can get pretty creative in your EDA visualizations, but for now we will create a simple boxplot showing our summary statistics using the library matplotlib."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, left, right, rule):\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.feature = rule[0]\n",
    "        self.threshold = rule[1]\n",
    "\n",
    "\n",
    "class Leaf:\n",
    "    def __init__(self, value):\n",
    "        \"\"\"\n",
    "        `value` is an array of class probabilities if classifier is True, else\n",
    "        the mean of the region\n",
    "        \"\"\"\n",
    "        self.value = value\n",
    "\n",
    "\n",
    "class DecisionTree:\n",
    "    def __init__(\n",
    "        self,\n",
    "        classifier=True,\n",
    "        max_depth=None,\n",
    "        n_feats=None,\n",
    "        criterion=\"entropy\",\n",
    "        seed=None,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        A decision tree model for regression and classification problems.\n",
    "        Parameters\n",
    "        ----------\n",
    "        classifier : bool\n",
    "            Whether to treat target values as categorical (classifier =\n",
    "            True) or continuous (classifier = False). Default is True.\n",
    "        max_depth: int or None\n",
    "            The depth at which to stop growing the tree. If None, grow the tree\n",
    "            until all leaves are pure. Default is None.\n",
    "        n_feats : int\n",
    "            Specifies the number of features to sample on each split. If None,\n",
    "            use all features on each split. Default is None.\n",
    "        criterion : {'mse', 'entropy', 'gini'}\n",
    "            The error criterion to use when calculating splits. When\n",
    "            `classifier` is False, valid entries are {'mse'}. When `classifier`\n",
    "            is True, valid entries are {'entropy', 'gini'}. Default is\n",
    "            'entropy'.\n",
    "        seed : int or None\n",
    "            Seed for the random number generator. Default is None.\n",
    "        \"\"\"\n",
    "        if seed:\n",
    "            np.random.seed(seed)\n",
    "\n",
    "        self.depth = 0\n",
    "        self.root = None\n",
    "\n",
    "        self.n_feats = n_feats\n",
    "        self.criterion = criterion\n",
    "        self.classifier = classifier\n",
    "        self.max_depth = max_depth if max_depth else np.inf\n",
    "\n",
    "        if not classifier and criterion in [\"gini\", \"entropy\"]:\n",
    "            raise ValueError(\n",
    "                \"{} is a valid criterion only when classifier = True.\".format(criterion)\n",
    "            )\n",
    "        if classifier and criterion == \"mse\":\n",
    "            raise ValueError(\"`mse` is a valid criterion only when classifier = False.\")\n",
    "\n",
    "    def fit(self, X, Y):\n",
    "        \"\"\"\n",
    "        Fit a binary decision tree to a dataset.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : :py:class:`ndarray <numpy.ndarray>` of shape `(N, M)`\n",
    "            The training data of `N` examples, each with `M` features\n",
    "        Y : :py:class:`ndarray <numpy.ndarray>` of shape `(N,)`\n",
    "            An array of integer class labels for each example in `X` if\n",
    "            self.classifier = True, otherwise the set of target values for\n",
    "            each example in `X`.\n",
    "        \"\"\"\n",
    "        self.n_classes = max(Y) + 1 if self.classifier else None\n",
    "        self.n_feats = X.shape[1] if not self.n_feats else min(self.n_feats, X.shape[1])\n",
    "        self.root = self._grow(X, Y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Use the trained decision tree to classify or predict the examples in `X`.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : :py:class:`ndarray <numpy.ndarray>` of shape `(N, M)`\n",
    "            The training data of `N` examples, each with `M` features\n",
    "        Returns\n",
    "        -------\n",
    "        preds : :py:class:`ndarray <numpy.ndarray>` of shape `(N,)`\n",
    "            The integer class labels predicted for each example in `X` if\n",
    "            self.classifier = True, otherwise the predicted target values.\n",
    "        \"\"\"\n",
    "        return np.array([self._traverse(x, self.root) for x in X])\n",
    "\n",
    "    def predict_class_probs(self, X):\n",
    "        \"\"\"\n",
    "        Use the trained decision tree to return the class probabilities for the\n",
    "        examples in `X`.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : :py:class:`ndarray <numpy.ndarray>` of shape `(N, M)`\n",
    "            The training data of `N` examples, each with `M` features\n",
    "        Returns\n",
    "        -------\n",
    "        preds : :py:class:`ndarray <numpy.ndarray>` of shape `(N, n_classes)`\n",
    "            The class probabilities predicted for each example in `X`.\n",
    "        \"\"\"\n",
    "        assert self.classifier, \"`predict_class_probs` undefined for classifier = False\"\n",
    "        return np.array([self._traverse(x, self.root, prob=True) for x in X])\n",
    "\n",
    "    def _grow(self, X, Y):\n",
    "        # if all labels are the same, return a leaf\n",
    "        if len(set(Y)) == 1:\n",
    "            if self.classifier:\n",
    "                prob = np.zeros(self.n_classes)\n",
    "                prob[Y[0]] = 1.0\n",
    "            return Leaf(prob) if self.classifier else Leaf(Y[0])\n",
    "\n",
    "        # if we have reached max_depth, return a leaf\n",
    "        if self.depth >= self.max_depth:\n",
    "            v = np.mean(Y, axis=0)\n",
    "            if self.classifier:\n",
    "                v = np.bincount(Y, minlength=self.n_classes) / len(Y)\n",
    "            return Leaf(v)\n",
    "\n",
    "        N, M = X.shape\n",
    "        self.depth += 1\n",
    "        feat_idxs = np.random.choice(M, self.n_feats, replace=False)\n",
    "\n",
    "        # greedily select the best split according to `criterion`\n",
    "        feat, thresh = self._segment(X, Y, feat_idxs)\n",
    "        l = np.argwhere(X[:, feat] <= thresh).flatten()\n",
    "        r = np.argwhere(X[:, feat] > thresh).flatten()\n",
    "\n",
    "        # grow the children that result from the split\n",
    "        left = self._grow(X[l, :], Y[l])\n",
    "        right = self._grow(X[r, :], Y[r])\n",
    "        return Node(left, right, (feat, thresh))\n",
    "\n",
    "    def _segment(self, X, Y, feat_idxs):\n",
    "        \"\"\"\n",
    "        Find the optimal split rule (feature index and split threshold) for the\n",
    "        data according to `self.criterion`.\n",
    "        \"\"\"\n",
    "        best_gain = -np.inf\n",
    "        split_idx, split_thresh = None, None\n",
    "        for i in feat_idxs:\n",
    "            vals = X[:, i]\n",
    "            levels = np.unique(vals)\n",
    "            thresholds = (levels[:-1] + levels[1:]) / 2 if len(levels) > 1 else levels\n",
    "            gains = np.array([self._impurity_gain(Y, t, vals) for t in thresholds])\n",
    "\n",
    "            if gains.max() > best_gain:\n",
    "                split_idx = i\n",
    "                best_gain = gains.max()\n",
    "                split_thresh = thresholds[gains.argmax()]\n",
    "\n",
    "        return split_idx, split_thresh\n",
    "\n",
    "    def _impurity_gain(self, Y, split_thresh, feat_values):\n",
    "        \"\"\"\n",
    "        Compute the impurity gain associated with a given split.\n",
    "        IG(split) = loss(parent) - weighted_avg[loss(left_child), loss(right_child)]\n",
    "        \"\"\"\n",
    "        if self.criterion == \"entropy\":\n",
    "            loss = entropy\n",
    "        elif self.criterion == \"gini\":\n",
    "            loss = gini\n",
    "        elif self.criterion == \"mse\":\n",
    "            loss = mse\n",
    "\n",
    "        parent_loss = loss(Y)\n",
    "\n",
    "        # generate split\n",
    "        left = np.argwhere(feat_values <= split_thresh).flatten()\n",
    "        right = np.argwhere(feat_values > split_thresh).flatten()\n",
    "\n",
    "        if len(left) == 0 or len(right) == 0:\n",
    "            return 0\n",
    "\n",
    "        # compute the weighted avg. of the loss for the children\n",
    "        n = len(Y)\n",
    "        n_l, n_r = len(left), len(right)\n",
    "        e_l, e_r = loss(Y[left]), loss(Y[right])\n",
    "        child_loss = (n_l / n) * e_l + (n_r / n) * e_r\n",
    "\n",
    "        # impurity gain is difference in loss before vs. after split\n",
    "        ig = parent_loss - child_loss\n",
    "        return ig\n",
    "\n",
    "    def _traverse(self, X, node, prob=False):\n",
    "        if isinstance(node, Leaf):\n",
    "            if self.classifier:\n",
    "                return node.value if prob else node.value.argmax()\n",
    "            return node.value\n",
    "        if X[node.feature] <= node.threshold:\n",
    "            return self._traverse(X, node.left, prob)\n",
    "        return self._traverse(X, node.right, prob)\n",
    "\n",
    "\n",
    "def mse(y):\n",
    "    \"\"\"\n",
    "    Mean squared error for decision tree (ie., mean) predictions\n",
    "    \"\"\"\n",
    "    return np.mean((y - np.mean(y)) ** 2)\n",
    "\n",
    "\n",
    "def entropy(y):\n",
    "    \"\"\"\n",
    "    Entropy of a label sequence\n",
    "    \"\"\"\n",
    "    hist = np.bincount(y)\n",
    "    ps = hist / np.sum(hist)\n",
    "    return -np.sum([p * np.log2(p) for p in ps if p > 0])\n",
    "\n",
    "\n",
    "def gini(y):\n",
    "    \"\"\"\n",
    "    Gini impurity (local entropy) of a label sequence\n",
    "    \"\"\"\n",
    "    hist = np.bincount(y)\n",
    "    N = np.sum(hist)\n",
    "    return 1 - sum([(i / N) ** 2 for i in hist])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "iris = datasets.load_iris()\n",
    "x = iris.data\n",
    "y = iris.target\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=.5)\n",
    "dt.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 2, 2, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 2, 2, 1, 0, 2, 0, 0, 0,\n",
       "       0, 2, 1, 2, 2, 1, 0, 1, 0, 1, 2, 1, 1, 1, 2, 1, 2, 0, 0, 2, 0, 1,\n",
       "       0, 2, 2, 2, 0, 0, 0, 1, 1, 1, 2, 1, 2, 1, 2, 0, 2, 2, 2, 2, 2, 0,\n",
       "       0, 2, 0, 0, 1, 2, 1, 1, 2])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions=lr.predict(dt_test)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9466666666666667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
